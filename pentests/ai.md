title: AI notes
author: gros
layout: default
---


### Machine Learning:
    - supervised learning (given some input features, some target features, and a set of training examples where the input features and the target features are specified, predict the value of target features for new examples given their values on the input features)
        - classification (target features are discrete)
        - regression (target features are continuous)
    - unsupervised learning (examples do not have targets defined / natural classification of data)
    - reinforcement learning (learning what to do based on rewards and punishments )
    - analytic learning (learning to reason faster )
    - inductive logic programming (learning richer representations)

### Reasoning:
    - induction (inferring an internal representation based on examples )
    - deduction (deriving consequences of a knowledge base)
    - abduction (hypothesizing what may be true about a particular case)


==============================================
## Supervised Machine Learning
    • a set of input features (X1,..,Xn)
    • a set of target features (Y1,..,Yn)
    • a set of training examples (e is example) ( (X1(e1),..,Xn(e1), Y1(e1),..,Yn(e1)), ... ,(X1(em),..,Xn(em), Y1(em),..,Yn(em)) )
    • a set of test examples ( (X1(em+1),..,Xn(em+1)), ... ,(X1(ez),..,Xn(ez)) )

    f.e.
    e       X1     X2     Y1
    Example Authro Thread User_action
    e1      known  new    skips
    e2      known  old    reads
    e3      unknown new   ?


#### Evaluating Predictions
    Y(e) - value of target future on example e
    Y'(e) - point estimate - predicted value for target feature Y on example e
    E - is a set of examples
    T - is a set of target features

    0/1 error - L0 error (norm)
    sum Y(e) != Y'(e) :for e in E, for Y in T

    absolute error - L1 error (norm)
    sum |Y(e) - Y'(e)| :for e in E, for Y in T

    sum-of-squares error - L2 error (norm)
    sum (Y(e) - Y'(e))^2 :for e in E, for Y in T

    worst-case error - Linf error (norm)
    max |Y(e) - Y'(e)| :for e in E, for Y in T


#### Types of errors
_________________| actual positive | actual negative
predict positive | true positive   | false positive
predict negative | false negative  | false negative


#### Learned model (function from the input features to the target features)

==============================================

## Unsupervised Machine Learning

    methods:
    - clustering (partitions examples into clusters or classes)
    